+++
title = 'Are We There Yet - Some random thoughts on AI'
date = 2024-04-21T23:02:48-04:00
draft = true
+++

Humanity has long harbored a fervent desire to fly, a dream mirrored in the design of modern airplanes, which, while distinct from birds, echo their graceful forms. Similarly, the pursuit of artificial intelligence (AI) draws inspiration from the intricate workings of the human brain, propelling the evolution of artificial neural networks. Yet, akin to the turbulent history of AI marked by periods of progress and stagnation (see [AI winter](https://en.wikipedia.org/wiki/AI_winter)), we find ourselves on the cusp of a new frontier where AI's capabilities begin to emulate human cognition. However, as AI reaches new heights, concerns emerge among leading researchers about its potential to surpass human control, echoing echoes reminiscent of the cautionary tales of the past.

Being inherently contrarian and a perpetual learner, I find myself pondering whether AI has indeed reached a juncture where it surpasses human intelligence, akin to airplanes soaring higher and faster than birds.

History provides a comprehensive timeline detailing the evolution of airplanes (refer to [wikipedia airplane](https://en.wikipedia.org/wiki/Airplane)). Though admittedly, as a layman in both AI and aerospace engineering, I recognize the substantial theoretical groundwork underpinning the success of airplanes, including the intricate field of [aerodynamics](https://en.wikipedia.org/wiki/Aerodynamics). Moreover, even in the $21^{st}$ century, companies persist in refining airplane quality through ongoing efforts. Well, the Boeing quality scandals. 

How about AI? Is it at a stage of maturity where it can reliably serve as a high-quality product or service? Perhaps the primary prerequisite lies in the foundational theories surrounding AI and machine learning, which still appear somewhat nascent. It's widely acknowledged that there's a dearth of understanding regarding the predictability of current machine learning models. From an engineer's perspective, this presents a notable quality concern.

Quality should never be compromised, unless, of course, the end user's indifference permits it. When we perceive machine learning systems as a subset of software systems, albeit with enigmatic rules defying thorough interpretation, the optimal approach for human society is to manage quality in light of the absence of a well-defined theory outlining the behavior of these systems. Consequently, the focus shifts towards people and processes rather than technology. In such instances of management, it entails leveraging our best efforts—monitoring and intervening as necessary—to uphold quality standards.

So, are we there yet? If I dare to offer a layman's perspective, my humble answer would be a resounding no, at least not from the standpoint of quality management.

Disclaimer: This writing has been assisted by ChatGPT.

